name: Telegram Web Scraper (自动/手动运行 - 上海时区)

on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - 'scraper_web.py'
      - 'requirements.txt'

jobs:
  scrape_and_save:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
      - name: 检出代码 (Fetch Full History)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 

      - name: 安装 Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: 安装依赖
        run: pip install -r requirements.txt

      - name: 清理超过 7 天的旧文件
        run: |
          echo "开始清理超过 7 天的旧文件..."
          find . -type f -path '*/*/*.md' -mtime +7 -delete
          find . -type f -path '*/*/*.json' -mtime +7 -delete
          find . -type f -path '*/*/media/*' -mtime +7 -delete
          find . -type d -empty -delete
          echo "清理完成。"

      - name: 运行 Web 抓取脚本
        run: python scraper_web.py
        
      - name: 提交生成的 Markdown、JSON 和媒体文件
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "自动维护 [Schedule]: 清理旧文件并抓取最新内容 (${{ env.TZ }})"
          file_pattern: |
            */*/*.md
            */*/*.json
            */*/media/*
          commit_author: "GitHub Actions Bot <github-actions[bot]@users.noreply.github.com>"
