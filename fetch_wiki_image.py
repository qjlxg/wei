import requests
from datetime import datetime, timedelta
import pytz
import json
import os
import re

# --- é…ç½® ---
# è®¾ç½®æ—¶åŒºä¸ºä¸Šæµ·
SHANGHAI_TZ = pytz.timezone('Asia/Shanghai')
# ç»´åŸºå…±äº«èµ„æº API
API_ENDPOINT = "https://commons.wikimedia.org/w/api.php"
# å¿…é¡»è®¾ç½® User-Agentï¼Œè¯·æ›¿æ¢ä¸ºæ‚¨çš„è”ç³»é‚®ç®±
HEADERS = {
    'User-Agent': 'GitHubActionWikiPotdBatchDownloader/5.0 (contact: YourContact@example.com)'
}
# å­˜å‚¨å›¾ç‰‡çš„æ ¹ç›®å½•
BASE_DOWNLOAD_DIR = 'wiki_image'
# å¼€å§‹æ‰¹é‡ä¸‹è½½çš„å¹´ä»½ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
START_YEAR = 2024

# MIME ç±»å‹åˆ°æ–‡ä»¶æ‰©å±•åçš„æ˜ å°„
MIME_TO_EXT = {
    'image/jpeg': '.jpg',
    'image/png': '.png',
    'image/gif': '.gif',
    'image/svg+xml': '.svg',
    # æ·»åŠ å…¶ä»–æ ¼å¼...
    'application/octet-stream': '.bin' # é»˜è®¤æœªçŸ¥ç±»å‹
}
# --- é…ç½®ç»“æŸ ---


def get_potd_filename(date_str):
    """
    ç¬¬ä¸€æ­¥ï¼šé€šè¿‡å±•å¼€ POTD æ¨¡æ¿è·å–å½“å¤©çš„å›¾ç‰‡æ–‡ä»¶å (æ¥è‡ª Wikimedia Commons)ã€‚
    """
    template_text = f"{{{{Potd/{date_str}}}}}"
    params = {
        "action": "expandtemplates",
        "format": "json",
        "prop": "wikitext",
        "text": template_text
    }
    
    response = requests.get(API_ENDPOINT, headers=HEADERS, params=params)
    response.raise_for_status()
    data = response.json()
    
    expand_data = data.get('expandtemplates', {})
    wikitext_node = expand_data.get('wikitext')
    
    wikitext = ''
    
    if isinstance(wikitext_node, dict):
        wikitext = wikitext_node.get('*', '').strip()
    elif isinstance(wikitext_node, str):
        wikitext = wikitext_node.strip()
        
    if not wikitext:
        # å¦‚æœæ¨¡æ¿å±•å¼€ä¸ºç©ºï¼Œå¯èƒ½æ˜¯è¯¥æ—¥æ²¡æœ‰ POTDï¼Œè¿™åœ¨å†å²æ•°æ®ä¸­å¾ˆå¸¸è§
        raise ValueError(f"æ— æ³•å±•å¼€ POTD æ¨¡æ¿ ({date_str})ã€‚")
        
    return wikitext

def get_image_details(filename):
    """
    ç¬¬äºŒæ­¥ï¼šè·å–å›¾ç‰‡æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯ã€URL å’Œ MIME ç±»å‹ã€‚
    """
    params = {
        "action": "query",
        "format": "json",
        "titles": f"File:{filename}",
        "prop": "imageinfo",
        "iiprop": "url|extmetadata|mime|size"
    }
    
    response = requests.get(API_ENDPOINT, headers=HEADERS, params=params)
    response.raise_for_status()
    data = response.json()
    
    pages = data.get('query', {}).get('pages', {})
    if not pages:
         raise ValueError(f"API è¿”å›çš„æŸ¥è¯¢ç»“æœä¸­æœªæ‰¾åˆ°é¡µé¢ä¿¡æ¯ã€‚")

    page_id = next(iter(pages))
    page_info = pages[page_id]
    
    if page_id == '-1':
        raise ValueError(f"API æ‰¾ä¸åˆ°æ–‡ä»¶: {filename}")
        
    image_info = page_info.get('imageinfo', [{}])[0]
    
    if not image_info:
        raise ValueError(f"æ— æ³•è·å–æ–‡ä»¶è¯¦æƒ…: {filename}")
        
    caption_raw = image_info.get('extmetadata', {}).get('Caption', {}).get('value', 'N/A')
    caption = re.sub('<[^<]+?>', '', caption_raw)

    return {
        'title': page_info.get('title'),
        'url': image_info.get('url'),
        'mime': image_info.get('mime'),
        'caption': caption.strip()
    }

def download_image_file(url, mime_type, target_dir, date_str):
    """
    ä¸‹è½½å›¾ç‰‡æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨æ—¥æœŸä½œä¸ºæ–‡ä»¶ååŸºå‡†ã€‚
    """
    ext = MIME_TO_EXT.get(mime_type, '.bin')
    # æ–‡ä»¶åæ ¼å¼ï¼šYYYY-MM-DD.ext
    file_name = date_str + ext
    file_path = os.path.join(target_dir, file_name)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå®ç°å¢é‡æ›´æ–°
    if os.path.exists(file_path):
        print(f"   [SKIP] å›¾ç‰‡å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {file_path}")
        return file_path
        
    print(f"   [DL] æ­£åœ¨ä¸‹è½½å›¾ç‰‡åˆ° {file_path}...")
    
    # ä¸‹è½½è¯·æ±‚
    img_response = requests.get(url, stream=True, headers=HEADERS)
    img_response.raise_for_status()
    
    # å†™å…¥æ–‡ä»¶
    with open(file_path, 'wb') as f:
        for chunk in img_response.iter_content(chunk_size=8192):
            f.write(chunk)
            
    print(f"   [DONE] å›¾ç‰‡æ–‡ä»¶ä¸‹è½½å¹¶ä¿å­˜å®Œæˆã€‚")
    return file_path


def save_metadata(details, date_str, target_dir):
    """
    ä¿å­˜å›¾ç‰‡çš„å…ƒæ•°æ®æ–‡ä»¶ã€‚
    """
    metadata_file_name = date_str + '_meta.txt'
    metadata_file_path = os.path.join(target_dir, metadata_file_name)
    
    # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(metadata_file_path):
        return
    
    result_content = (
        f"--- Wikimedia Commons Picture of the Day Metadata for {date_str} ---\n\n"
        f"File Name: {details['title'].replace('File:', '')}\n"
        f"Image URL: {details['url']}\n"
        f"MIME Type: {details['mime']}\n"
        f"Caption: {details['caption']}\n"
    )
    with open(metadata_file_path, 'w', encoding='utf-8') as f:
        f.write(result_content)


def process_date(current_date):
    """
    å¤„ç†ç‰¹å®šæ—¥æœŸçš„ POTD ä¸‹è½½å’Œä¿å­˜ã€‚
    """
    date_str = current_date.strftime('%Y-%m-%d')
    print(f"\n>>>> æ­£åœ¨å¤„ç†æ—¥æœŸ: {date_str} <<<<")
    
    # æ„é€ ç›®æ ‡ç›®å½•: BASE_DOWNLOAD_DIR/YYYY/MM/
    target_dir = os.path.join(
        BASE_DOWNLOAD_DIR,
        current_date.strftime('%Y'),
        current_date.strftime('%m')
    )
    os.makedirs(target_dir, exist_ok=True)
    
    try:
        # 1. è·å–æ–‡ä»¶å
        filename = get_potd_filename(date_str)
        
        # 2. è·å–å›¾ç‰‡è¯¦æƒ…
        details = get_image_details(filename)
        
        # 3. ä¸‹è½½å®é™…å›¾ç‰‡æ–‡ä»¶ï¼ˆåŒ…å«å­˜åœ¨æ€§æ£€æŸ¥å’Œè·³è¿‡é€»è¾‘ï¼‰
        download_image_file(
            url=details['url'],
            mime_type=details['mime'],
            target_dir=target_dir,
            date_str=date_str
        )
        
        # 4. ä¿å­˜å…ƒæ•°æ®
        save_metadata(details, date_str, target_dir)
        
    except ValueError as e:
        # æ— æ³•æ‰¾åˆ° POTD æ–‡ä»¶åï¼Œå¯èƒ½æ˜¯å½“æ—¥æ— å›¾ç‰‡ï¼Œè·³è¿‡
        print(f"   [FAIL] è·³è¿‡: {e}")
    except requests.exceptions.HTTPError as e:
        # ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œé€šå¸¸æ˜¯ 404 æˆ– 403
        print(f"   [FAIL] HTTP é”™è¯¯ {e.response.status_code}ï¼Œè·³è¿‡è¯¥æ—¥æœŸã€‚")
    except Exception as e:
        print(f"   [FAIL] å‘ç”Ÿæ„å¤–é”™è¯¯ï¼Œè·³è¿‡è¯¥æ—¥æœŸ: {e}")


def fetch_and_save_wiki_picture():
    """
    æ‰¹é‡è·å–ä» START_YEAR åˆ°ä»Šå¤©çš„æ‰€æœ‰æ¯æ—¥å›¾ç‰‡ã€‚
    """
    now_shanghai = datetime.now(SHANGHAI_TZ).replace(hour=0, minute=0, second=0, microsecond=0)
    
    # ç¡®å®šèµ·å§‹æ—¥æœŸ
    start_date = datetime(START_YEAR, 1, 1, tzinfo=SHANGHAI_TZ)
    
    # å¦‚æœèµ·å§‹å¹´ä»½æ™šäºå½“å‰å¹´ä»½ï¼Œåˆ™ä»¥èµ·å§‹å¹´ä»½ä¸ºå‡†ï¼Œå¦åˆ™ä»¥å½“å‰å¹´ä»½ä¸ºå‡†ï¼ˆé˜²æ­¢ä¸‹è½½æœªæ¥æ—¥æœŸï¼‰
    if start_date > now_shanghai:
        start_date = now_shanghai

    current_date = start_date
    
    print(f"ğŸ”¥ ä»»åŠ¡å¼€å§‹ï¼šä» {start_date.strftime('%Y-%m-%d')} åˆ° {now_shanghai.strftime('%Y-%m-%d')} æ‰¹é‡ä¸‹è½½ POTDã€‚")
    
    while current_date <= now_shanghai:
        process_date(current_date)
        current_date += timedelta(days=1)
        
    print("\nğŸ‰ æ‰¹é‡ä¸‹è½½ä»»åŠ¡å®Œæˆï¼")


if __name__ == "__main__":
    fetch_and_save_wiki_picture()
